{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F06ipkgGX7Ji"},"outputs":[],"source":["# mdoule 2 : Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"pOR_Dt5bX7Jn","outputId":"f6199f0e-322e-4711-c142-9747469f2ade","executionInfo":{"status":"ok","timestamp":1743158879435,"user_tz":-330,"elapsed":26313,"user":{"displayName":"Akash Panda","userId":"14065063236529144716"}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: nltk 3.9.1\n","Uninstalling nltk-3.9.1:\n","  Would remove:\n","    /usr/local/bin/nltk\n","    /usr/local/lib/python3.11/dist-packages/nltk-3.9.1.dist-info/*\n","    /usr/local/lib/python3.11/dist-packages/nltk/*\n","Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n","    uninstall_pathset = req.uninstall(\n","                        ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 722, in uninstall\n","    uninstalled_pathset.remove(auto_confirm, verbose)\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_uninstall.py\", line 364, in remove\n","    if auto_confirm or self._allowed_to_proceed(verbose):\n","                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_uninstall.py\", line 404, in _allowed_to_proceed\n","    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/misc.py\", line 235, in ask\n","    response = input(message)\n","               ^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n","    return command.main(cmd_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n","    return self._main(args)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n","    return run(options, args)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n","    logger.debug(\"Exception information:\", exc_info=True)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n","    msg = self.format(record)\n","          ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n","    return fmt.format(record)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n","    formatted = super().format(record)\n","                ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 695, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 645, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.11/traceback.py\", line 124, in print_exception\n","    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/traceback.py\", line 728, in __init__\n","    self.stack = StackSummary._extract_from_extended_frame_gen(\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/traceback.py\", line 433, in _extract_from_extended_frame_gen\n","    f.line\n","  File \"/usr/lib/python3.11/traceback.py\", line 318, in line\n","    self._line = linecache.getline(self.filename, self.lineno)\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","         ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 398, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 367, in detect_encoding\n","    first = read_or_stop()\n","            ^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 325, in read_or_stop\n","    return readline()\n","           ^^^^^^^^^^\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip uninstall nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8EEyeruX7Jq","outputId":"4316b309-9eec-4a8b-b288-a4bcd4e5b019","executionInfo":{"status":"ok","timestamp":1743146408387,"user_tz":-330,"elapsed":11088,"user":{"displayName":"Akash Panda","userId":"14065063236529144716"}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nltk\n","  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nltk\n","Successfully installed nltk-3.9.1\n"]}],"source":["!pip install -U nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KSMUFfqX7Js"},"outputs":[],"source":["import pandas as pd\n","import re\n","import numpy as np\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from collections import Counter\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xr_s-vjX7Jt"},"outputs":[],"source":["#nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsY6Mv9BX7Ju"},"outputs":[],"source":["#nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dY_h9qKyX7Jv"},"outputs":[],"source":["#from nltk.corpus import stopwords\n","#stop_words = set(stopwords.words(\"english\"))\n","#print(stop_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaIy_cHEX7Jw"},"outputs":[],"source":["stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n","            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n","            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n","            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n","            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n","            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n","            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n","            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n","            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n","            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n","            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n","            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n","            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n","            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n","            'won', \"won't\", 'wouldn', \"wouldn't\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3oU3vW0X7Jx"},"outputs":[],"source":["class Data_Preprocessing :\n","  def __init__(self) :\n","    self.p_stemmer = PorterStemmer()\n","    self.lemmatizer = WordNetLemmatizer()\n","\n","  # https://stackoverflow.com/a/47091490/4084039\n","  def decontracted(self , phrase):\n","    # specific\n","    phrase = re.sub(r\"won't\", \"will not\", phrase)      # replace won't with \"will not\"\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)      # replace can or cant with 'can not'\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)           # replece n with 'not'\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)           # replace re with 'are'\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)             # replace s with 'is'\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)          # replace 'd' with 'would'\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)          # replace 'll with 'will'\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)            # replace 't' with 'not'\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)          # replace ve with 'have'\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)             # replace 'm with 'am'\n","    return phrase\n","\n","\n","  def preprocess_text(self,text_data):\n","    preprocessed_text = []\n","    # tqdm is for printing the status bar\n","    for sentance in tqdm(text_data):\n","        sent = self.decontracted(sentance)           #calling funcion for each sentence\n","        #print(\"1st sent\" , sent)\n","        sent = sent.replace('\\\\r', ' ')         # replace line terminator with space\n","        sent = sent.replace('\\\\n', ' ')         # replace new line charactor with space\n","        sent = sent.replace('\\\\\"', ' ')\n","        sent = re.sub('[^A-Za-z]+', ' ', sent)  # remove anything that is not letter\n","        sent = ''.join(self.p_stemmer.stem(token) for token in sent )\n","        sent = ''.join(self.lemmatizer.lemmatize(token) for token in sent )\n","        sent  = ' '.join(e for e in sent.split() if len( Counter(e)) > 2 )\n","        #sent = lstr(emmatize_text(sent)\n","        # https://gist.github.com/sebleier/554280\n","        sent = ' '.join(e for e in sent.split() if e.lower() not in 'root/nltk_data/corpora/stop_words') # checking for stop words\n","        preprocessed_text.append(sent.lower().strip())\n","    return preprocessed_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mviSxt4TX7Jz"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}